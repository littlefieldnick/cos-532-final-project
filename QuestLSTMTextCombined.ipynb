{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from  torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.data import TabularDataset, BucketIterator\n",
    "from torch.utils.data import DataLoader\n",
    "import gensim\n",
    "from nltk.tokenize import TreebankWordTokenizer, WhitespaceTokenizer\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_processed.csv\")\n",
    "test = pd.read_csv(\"data/test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PTH = \"data/\"\n",
    "TRAIN = \"train_processed.csv\"\n",
    "TEST = \"test_processed.csv\"\n",
    "EMB_FILE = \"embeddings_processed.txt\"\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# word2vec Params\n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 150\n",
    "W2V_MIN_COUNT = 2\n",
    "\n",
    "LABEL_THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_question_columns = [\n",
    "       'question_asker_intent_understanding',\n",
    "       'question_body_critical', 'question_conversational',\n",
    "       'question_expect_short_answer', 'question_fact_seeking',\n",
    "       'question_has_commonly_accepted_answer',\n",
    "       'question_interestingness_others', 'question_interestingness_self',\n",
    "       'question_multi_intent', 'question_not_really_a_question',\n",
    "       'question_opinion_seeking', 'question_type_choice',\n",
    "       'question_type_compare', 'question_type_consequence',\n",
    "       'question_type_definition', 'question_type_entity',\n",
    "       'question_type_instructions', 'question_type_procedure',\n",
    "       'question_type_reason_explanation', 'question_type_spelling',\n",
    "       'question_well_written'\n",
    "]\n",
    "    \n",
    "target_answer_columns = [\n",
    "       'answer_helpful',\n",
    "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "       'answer_satisfaction', 'answer_type_instructions',\n",
    "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
    "       'answer_well_written'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_torchtext_fields():\n",
    "    text_tokenizer=TreebankWordTokenizer().tokenize\n",
    "    label_tokenizer = WhitespaceTokenizer().tokenize\n",
    "    \n",
    "    text_field = data.Field(sequential=True, tokenize=text_tokenizer, use_vocab=True,\n",
    "                           batch_first=True, include_lengths=False)\n",
    "    label_field = data.LabelField()\n",
    "    index_field = data.Field(sequential=False, dtype=torch.int, use_vocab=False)\n",
    "    \n",
    "    return text_field, label_field, index_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_w2v_documents(pth_to_train, columns, tokenizer):\n",
    "    train = pd.read_csv(pth_to_train, usecols=columns)\n",
    "    documents = []\n",
    "    for col in columns:\n",
    "        documents = documents + [tokenizer.tokenize(text) for text in train[col]]\n",
    "\n",
    "    return documents\n",
    "\n",
    "def build_w2v_model(pth_to_train, columns, save_embeddings=False):\n",
    "    docs = build_w2v_documents(pth_to_train, columns, TreebankWordTokenizer())\n",
    "\n",
    "    # Train Word Embeddings and save\n",
    "    w2v = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                          window=W2V_WINDOW,                                                                                  \n",
    "                                          min_count=W2V_MIN_COUNT)\n",
    "    w2v.build_vocab(docs)\n",
    "    words = w2v.wv.vocab.keys()\n",
    "    vocab_size = len(words)\n",
    "    print(\"Vocab size\", vocab_size)\n",
    "\n",
    "    # Train Word Embeddings\n",
    "    w2v.train(docs, total_examples=len(docs), epochs=W2V_EPOCH)\n",
    "    \n",
    "    if save_embeddings:\n",
    "        w2v.save(DATA_PTH + EMB_FILE)\n",
    "\n",
    "    return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    if os.path.exists(DATA_PTH + EMB_FILE):\n",
    "        w2v_model = gensim.models.Word2Vec.load(DATA_PTH + EMB_FILE)\n",
    "    else:\n",
    "        w2v_model = build_w2v_model(DATA_PTH + TRAIN, \n",
    "                                   [\"TEXT\"], \n",
    "                                   save_embeddings=True)\n",
    "    \n",
    "    txt, label, idx = define_torchtext_fields()\n",
    "\n",
    "    predictor_columns = [\n",
    "        ('qa_id', idx),\n",
    "        ('TEXT', txt)\n",
    "    ]\n",
    "  \n",
    "    labels = [('labels', label)]\n",
    "\n",
    " \n",
    "    train_val_cols = predictor_columns + labels\n",
    "    test_cols = predictor_columns\n",
    "    \n",
    "    train_ds, valid_ds = TabularDataset(DATA_PTH + TRAIN, \n",
    "                                        format=\"csv\", \n",
    "                                        fields=train_val_cols, skip_header=True).split(split_ratio=0.7)\n",
    "    test_ds = TabularDataset(DATA_PTH + TEST, format=\"csv\", skip_header=True, fields=test_cols)\n",
    "    \n",
    "    txt.build_vocab(train_ds, valid_ds, min_freq=W2V_MIN_COUNT)\n",
    "    label.build_vocab(train_ds)\n",
    "    print(label.vocab.stoi)\n",
    "    word2vec_vectors = []\n",
    "    for token, idx in txt.vocab.stoi.items():\n",
    "        if token in w2v_model.wv.vocab.keys():\n",
    "            word2vec_vectors.append(torch.FloatTensor(w2v_model[token]))\n",
    "        else:\n",
    "            word2vec_vectors.append(torch.zeros(W2V_SIZE))\n",
    "    txt.vocab.set_vectors(txt.vocab.stoi, word2vec_vectors, W2V_SIZE)\n",
    "    \n",
    "    return train_ds, valid_ds, test_ds, txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'answer_relevance': 0, 'answer_plausible': 1, 'answer_well_written': 2, 'answer_helpful': 3, 'question_asker_intent_understanding': 4, 'answer_satisfaction': 5, 'question_well_written': 6, 'answer_level_of_information': 7, 'question_has_commonly_accepted_answer': 8, 'question_fact_seeking': 9, 'question_expect_short_answer': 10, 'question_interestingness_others': 11, 'question_body_critical': 12, 'question_type_instructions': 13, 'answer_type_reason_explanation': 14, 'answer_type_instructions': 15, 'question_opinion_seeking': 16, 'question_interestingness_self': 17, 'question_type_reason_explanation': 18, 'question_type_choice': 19, 'question_multi_intent': 20, 'question_type_procedure': 21, 'answer_type_procedure': 22, 'question_type_entity': 23, 'question_conversational': 24, 'question_type_compare': 25, 'question_type_definition': 26, 'question_type_consequence': 27, 'question_not_really_a_question': 28, 'question_type_spelling': 29})\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds, test_ds, vocab = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4255, 1824, 476, 40072)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds), len(test_ds), len(vocab.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['question_asker_intent_understanding', 'question_body_critical',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_type_instructions', 'question_well_written',\n",
       "       'answer_helpful', 'answer_level_of_information',\n",
       "       'answer_plausible', 'answer_relevance', 'answer_satisfaction',\n",
       "       'answer_type_reason_explanation', 'answer_well_written'],\n",
       "      dtype='<U37')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.examples[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BucketIterator(train_ds, \n",
    "                          batch_size=64, shuffle=True,\n",
    "                          sort_key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = BucketIterator(valid_ds, \n",
    "                          batch_size=64, shuffle=True,\n",
    "                          sort_key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = BucketIterator(test_ds, batch_size=32, shuffle=False, sort_key=lambda x: len(x.TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-f33cfa67f345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/qa_quest/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/qa_quest/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/qa_quest/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/qa_quest/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/qa_quest/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 14, 12,  ...,  1,  1,  1],\n",
       "        [ 6, 11, 13,  ..., 16,  4,  1],\n",
       "        [ 6, 14, 12,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 6, 14, 11,  ...,  4,  1,  1],\n",
       "        [ 6, 14, 12,  ...,  7,  4,  1],\n",
       "        [ 6, 12, 11,  ...,  1,  1,  1]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEmbedding(nn.Module):\n",
    "    def __init__(self, embedding, output_size, hidden_size=128, num_layers=3, dropout=0.3, bidir=False):\n",
    "        super(LSTMEmbedding, self).__init__()\n",
    "        self.bidirectional = bidir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.emb = nn.Embedding.from_pretrained(torch.FloatTensor(embedding), padding_idx=1, freeze=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding.size(1), hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidir,\n",
    "                            dropout=dropout, batch_first=True)\n",
    "      \n",
    "       \n",
    "        if bidir:\n",
    "            self.linear_in = hidden_size*2\n",
    "        else:\n",
    "            self.linear_in = hidden_size\n",
    "            \n",
    "        self.classifier = nn.Sequential(nn.Linear(self.linear_in, self.linear_in//2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64, output_size))\n",
    "    \n",
    "    def forward(self, x)\n",
    "        out = self.emb(x)\n",
    "        \n",
    "        out, hidden = self.lstm(x)\n",
    "\n",
    "        out = self.classifier(hidden)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMEmbedding(vocab.vocab.vectors, 30, num_layers=3, hidden_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_epoch_results(epoch, tl, vl, spear_t, spear_v):\n",
    "    if epoch == 1:\n",
    "        print(\"\\tTrain\\t\\tValidation\")\n",
    "        print(\"Epoch | Loss | Spear. | Loss | Spear.\")\n",
    "    \n",
    "    raw_line = '{:6d}' + '\\u2502{:6.3f}' * 4\n",
    "    print(raw_line.format(epoch, tl, spear_t, vl, spear_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_correlation_metric(predicted, true):\n",
    "    score = 0.\n",
    "    for i in range(predicted.shape[1]):\n",
    "        score += np.nan_to_num(spearmanr(predicted[:, i], true[:,i])[0])\n",
    "    \n",
    "    return score / 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_target_tensor(batch):\n",
    "    return torch.stack([getattr(batch, label) for label in target_question_columns +  target_answer_columns], dim=-1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, learning_rate, epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting training of model...\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        train_spearman = []\n",
    "        valid_spearman = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            qt = batch.question_title.cuda()\n",
    "            qb = batch.question_body.cuda()\n",
    "            qa = batch.answer.cuda()\n",
    "            targets = get_target_tensor(batch)\n",
    "            \n",
    "            out = model(qb, qa) #, qt_h, qb_h, qa_h)\n",
    "            print(out)\n",
    "            loss = criterion(out, targets)\n",
    "            train_loss.append(loss.item())\n",
    "            train_spearman.append(spearman_correlation_metric(out.detach().cpu().numpy(),\n",
    "                                                             targets.detach().cpu().numpy()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            \n",
    "        for batch in valid_loader:\n",
    "            qt = batch.question_title.cuda()\n",
    "            qb = batch.question_body.cuda()\n",
    "            qa = batch.answer.cuda()\n",
    "            targets = get_target_tensor(batch)\n",
    "            out = model(qb, qa)\n",
    "            loss = criterion(out, targets)\n",
    "            valid_spearman.append(spearman_correlation_metric(out.detach().cpu().numpy(),\n",
    "                                                             targets.detach().cpu().numpy()))\n",
    "            valid_loss.append(loss.item())\n",
    "            \n",
    "        print_epoch_results(epoch, np.array(train_loss).mean(), np.array(valid_loss).mean(), np.array(train_spearman).mean(),\n",
    "                            np.array(valid_spearman).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training of model...\n",
      "\tTrain\t\tValidation\n",
      "Epoch | Loss | Spear. | Loss | Spear.\n",
      "     1│ 0.463│ 0.024│ 0.425│ 0.048\n",
      "     2│ 0.422│ 0.054│ 0.424│ 0.077\n",
      "     3│ 0.421│ 0.086│ 0.423│ 0.140\n",
      "     4│ 0.410│ 0.166│ 0.406│ 0.195\n",
      "     5│ 0.402│ 0.202│ 0.405│ 0.193\n",
      "     6│ 0.398│ 0.220│ 0.402│ 0.211\n",
      "     7│ 0.394│ 0.230│ 0.401│ 0.211\n",
      "     8│ 0.392│ 0.241│ 0.402│ 0.225\n",
      "     9│ 0.388│ 0.261│ 0.400│ 0.233\n",
      "    10│ 0.385│ 0.283│ 0.398│ 0.251\n",
      "    11│ 0.379│ 0.307│ 0.396│ 0.265\n",
      "    12│ 0.374│ 0.329│ 0.397│ 0.272\n",
      "    13│ 0.368│ 0.349│ 0.396│ 0.275\n",
      "    14│ 0.363│ 0.368│ 0.398│ 0.277\n",
      "    15│ 0.358│ 0.382│ 0.398│ 0.271\n",
      "    16│ 0.353│ 0.396│ 0.399│ 0.277\n",
      "    17│ 0.349│ 0.409│ 0.399│ 0.283\n",
      "    18│ 0.345│ 0.422│ 0.399│ 0.285\n",
      "    19│ 0.342│ 0.435│ 0.402│ 0.285\n",
      "    20│ 0.338│ 0.448│ 0.403│ 0.286\n"
     ]
    }
   ],
   "source": [
    "train(model.cuda(), train_dl, valid_dl, 0.001, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/lstm-20ep-lr0-00025-hl-256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "test_preds = []\n",
    "for batch in test_dl:\n",
    "    qt = batch.question_title.cuda()\n",
    "    qb = batch.question_body.cuda()\n",
    "    qa = batch.answer.cuda()\n",
    "    out = model(qb, qa)\n",
    "    test_ids.extend(batch.qa_id.tolist())\n",
    "    test_preds.extend(torch.softmax(out, dim=-1).detach().cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.DataFrame({\"qa_id\": test_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(np.round(test_preds, 5))\n",
    "preds.columns = target_question_columns + target_answer_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15940</td>\n",
       "      <td>0.01491</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.01185</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00794</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>0.01277</td>\n",
       "      <td>0.00233</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05208</td>\n",
       "      <td>0.07831</td>\n",
       "      <td>0.01271</td>\n",
       "      <td>0.21257</td>\n",
       "      <td>0.20628</td>\n",
       "      <td>0.03241</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.03679</td>\n",
       "      <td>0.08760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02190</td>\n",
       "      <td>0.00346</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01320</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.11312</td>\n",
       "      <td>0.00374</td>\n",
       "      <td>0.00230</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00686</td>\n",
       "      <td>0.06679</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.12953</td>\n",
       "      <td>0.28269</td>\n",
       "      <td>0.02586</td>\n",
       "      <td>0.19842</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.02528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14270</td>\n",
       "      <td>0.02209</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.10350</td>\n",
       "      <td>0.04988</td>\n",
       "      <td>0.03544</td>\n",
       "      <td>0.01153</td>\n",
       "      <td>0.00953</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04170</td>\n",
       "      <td>0.07435</td>\n",
       "      <td>0.01334</td>\n",
       "      <td>0.17393</td>\n",
       "      <td>0.17752</td>\n",
       "      <td>0.03579</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.09247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02162</td>\n",
       "      <td>0.00298</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00948</td>\n",
       "      <td>0.04448</td>\n",
       "      <td>0.27829</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00761</td>\n",
       "      <td>0.08846</td>\n",
       "      <td>0.00668</td>\n",
       "      <td>0.17759</td>\n",
       "      <td>0.23778</td>\n",
       "      <td>0.03009</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>0.03001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06288</td>\n",
       "      <td>0.00943</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.01479</td>\n",
       "      <td>0.00933</td>\n",
       "      <td>0.00424</td>\n",
       "      <td>0.01029</td>\n",
       "      <td>0.00682</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02716</td>\n",
       "      <td>0.11956</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.24306</td>\n",
       "      <td>0.29325</td>\n",
       "      <td>0.04080</td>\n",
       "      <td>0.02486</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>0.08099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.04100</td>\n",
       "      <td>0.00573</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.01113</td>\n",
       "      <td>0.00618</td>\n",
       "      <td>0.00568</td>\n",
       "      <td>0.00572</td>\n",
       "      <td>0.00464</td>\n",
       "      <td>0.00032</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01304</td>\n",
       "      <td>0.07967</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>0.16359</td>\n",
       "      <td>0.29443</td>\n",
       "      <td>0.02722</td>\n",
       "      <td>0.20703</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.04636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.03933</td>\n",
       "      <td>0.01274</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.03159</td>\n",
       "      <td>0.20728</td>\n",
       "      <td>0.13287</td>\n",
       "      <td>0.01324</td>\n",
       "      <td>0.00807</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.08374</td>\n",
       "      <td>0.01515</td>\n",
       "      <td>0.11571</td>\n",
       "      <td>0.16219</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.01022</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.00647</td>\n",
       "      <td>0.05908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.04835</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.01896</td>\n",
       "      <td>0.11194</td>\n",
       "      <td>0.10350</td>\n",
       "      <td>0.01076</td>\n",
       "      <td>0.00665</td>\n",
       "      <td>0.01004</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02905</td>\n",
       "      <td>0.09084</td>\n",
       "      <td>0.01396</td>\n",
       "      <td>0.17282</td>\n",
       "      <td>0.17055</td>\n",
       "      <td>0.04554</td>\n",
       "      <td>0.01234</td>\n",
       "      <td>0.00613</td>\n",
       "      <td>0.01064</td>\n",
       "      <td>0.06333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.03072</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.02320</td>\n",
       "      <td>0.11297</td>\n",
       "      <td>0.34078</td>\n",
       "      <td>0.00433</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01029</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>0.00614</td>\n",
       "      <td>0.11889</td>\n",
       "      <td>0.17499</td>\n",
       "      <td>0.02756</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.03431</td>\n",
       "      <td>0.02699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.07366</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>0.03090</td>\n",
       "      <td>0.01391</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>0.00166</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03346</td>\n",
       "      <td>0.11501</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>0.21688</td>\n",
       "      <td>0.20386</td>\n",
       "      <td>0.04288</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.06643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_asker_intent_understanding  question_body_critical  \\\n",
       "0                                0.15940                 0.01491   \n",
       "1                                0.02190                 0.00346   \n",
       "2                                0.14270                 0.02209   \n",
       "3                                0.02162                 0.00298   \n",
       "4                                0.06288                 0.00943   \n",
       "..                                   ...                     ...   \n",
       "471                              0.04100                 0.00573   \n",
       "472                              0.03933                 0.01274   \n",
       "473                              0.04835                 0.00998   \n",
       "474                              0.03072                 0.00500   \n",
       "475                              0.07366                 0.01203   \n",
       "\n",
       "     question_conversational  question_expect_short_answer  \\\n",
       "0                    0.00164                       0.01185   \n",
       "1                    0.00000                       0.01320   \n",
       "2                    0.00017                       0.10350   \n",
       "3                    0.00000                       0.00948   \n",
       "4                    0.00022                       0.01479   \n",
       "..                       ...                           ...   \n",
       "471                  0.00004                       0.01113   \n",
       "472                  0.00004                       0.03159   \n",
       "473                  0.00005                       0.01896   \n",
       "474                  0.00001                       0.02320   \n",
       "475                  0.00008                       0.03018   \n",
       "\n",
       "     question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                  0.01050                                0.00794   \n",
       "1                  0.02100                                0.11312   \n",
       "2                  0.04988                                0.03544   \n",
       "3                  0.04448                                0.27829   \n",
       "4                  0.00933                                0.00424   \n",
       "..                     ...                                    ...   \n",
       "471                0.00618                                0.00568   \n",
       "472                0.20728                                0.13287   \n",
       "473                0.11194                                0.10350   \n",
       "474                0.11297                                0.34078   \n",
       "475                0.02659                                0.03090   \n",
       "\n",
       "     question_interestingness_others  question_interestingness_self  \\\n",
       "0                            0.01272                        0.01277   \n",
       "1                            0.00374                        0.00230   \n",
       "2                            0.01153                        0.00953   \n",
       "3                            0.00391                        0.00193   \n",
       "4                            0.01029                        0.00682   \n",
       "..                               ...                            ...   \n",
       "471                          0.00572                        0.00464   \n",
       "472                          0.01324                        0.00807   \n",
       "473                          0.01076                        0.00665   \n",
       "474                          0.00433                        0.00335   \n",
       "475                          0.01391                        0.01002   \n",
       "\n",
       "     question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                  0.00233                         0.00001  ...   \n",
       "1                  0.00008                         0.00001  ...   \n",
       "2                  0.00031                         0.00001  ...   \n",
       "3                  0.00023                         0.00001  ...   \n",
       "4                  0.00088                         0.00002  ...   \n",
       "..                     ...                             ...  ...   \n",
       "471                0.00032                         0.00001  ...   \n",
       "472                0.00068                         0.00025  ...   \n",
       "473                0.01004                         0.00003  ...   \n",
       "474                0.00049                         0.00000  ...   \n",
       "475                0.00166                         0.00004  ...   \n",
       "\n",
       "     question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0                  0.05208         0.07831                      0.01271   \n",
       "1                  0.00686         0.06679                      0.00594   \n",
       "2                  0.04170         0.07435                      0.01334   \n",
       "3                  0.00761         0.08846                      0.00668   \n",
       "4                  0.02716         0.11956                      0.01106   \n",
       "..                     ...             ...                          ...   \n",
       "471                0.01304         0.07967                      0.00704   \n",
       "472                0.02898         0.08374                      0.01515   \n",
       "473                0.02905         0.09084                      0.01396   \n",
       "474                0.01029         0.07005                      0.00614   \n",
       "475                0.03346         0.11501                      0.01393   \n",
       "\n",
       "     answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0             0.21257           0.20628              0.03241   \n",
       "1             0.12953           0.28269              0.02586   \n",
       "2             0.17393           0.17752              0.03579   \n",
       "3             0.17759           0.23778              0.03009   \n",
       "4             0.24306           0.29325              0.04080   \n",
       "..                ...               ...                  ...   \n",
       "471           0.16359           0.29443              0.02722   \n",
       "472           0.11571           0.16219              0.04775   \n",
       "473           0.17282           0.17055              0.04554   \n",
       "474           0.11889           0.17499              0.02756   \n",
       "475           0.21688           0.20386              0.04288   \n",
       "\n",
       "     answer_type_instructions  answer_type_procedure  \\\n",
       "0                     0.00005                0.00017   \n",
       "1                     0.19842                0.00025   \n",
       "2                     0.00015                0.00017   \n",
       "3                     0.00317                0.00059   \n",
       "4                     0.02486                0.00106   \n",
       "..                        ...                    ...   \n",
       "471                   0.20703                0.00026   \n",
       "472                   0.01022                0.00261   \n",
       "473                   0.01234                0.00613   \n",
       "474                   0.00016                0.00023   \n",
       "475                   0.04110                0.00167   \n",
       "\n",
       "     answer_type_reason_explanation  answer_well_written  \n",
       "0                           0.03679              0.08760  \n",
       "1                           0.00014              0.02528  \n",
       "2                           0.00257              0.09247  \n",
       "3                           0.03885              0.03001  \n",
       "4                           0.00103              0.08099  \n",
       "..                              ...                  ...  \n",
       "471                         0.00004              0.04636  \n",
       "472                         0.00647              0.05908  \n",
       "473                         0.01064              0.06333  \n",
       "474                         0.03431              0.02699  \n",
       "475                         0.00051              0.06643  \n",
       "\n",
       "[476 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = ids.join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
